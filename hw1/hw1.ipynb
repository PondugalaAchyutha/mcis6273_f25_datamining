{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Fall 2025 / HW1\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Monday September 15 @ Midnight | _up to_ 20 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Perform basic data engineering on the light pollution dataset.\n", "\n", "* Complete the online assessment\n", "\n", "* BONUS: Normalize column names in working dataset.\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw0`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw0_files.zip`, `maull_hw0_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (80%) Perform basic data engineering on the light pollution dataset. \n", "\n", "\n", "\n", "Continuing with our GaN dataset from the first assignment, \n", "we will now perform some data engineering.\n", "\n", "As has been discussed in the slide content on data engineering\n", "most often we are handed datasets which are less\n", "than perfect.  We might also have to deal with \n", "a more essential activity once it is perfect:\n", "determining if the dataset is sufficient to \n", "carry out the analysis we expect.\n", "\n", "There are a few important things you may have \n", "noticed about the dataset from the first\n", "assignment:\n", "\n", "1. the data files are separated; while this is\n", "  sometimes desirable, often it is more \n", "  desirable to have data in a single file \n", "  _when possible_,\n", "2. there are some categorical fields that are not numeric, \n", "   but could be which might improve the outcomes of algorithms\n", "   that do not accept non-numeric data,\n", "3. there are some fields that need combining for easier \n", "   access to date/time convenience functions in Pandas,\n", "4. there are some complex fields which contain\n", "   data that are may be better stored in there own field.\n", "\n", "\n", "You will want to study a sample CSV file yourself \n", "to determine other issues which might be worthy\n", "of consideration.\n", "\n", "For our data engineering we want to broadly \n", "complete the following:\n", "\n", "1. combine all the GaN files into a single file and thus a\n", "   single Pandas DataFrame,\n", "2. convert specific data fields to numeric fields using\n", "   Pandas,\n", "3. combine date and time fields for easier time series evaluation,\n", "3. split data out of specific fields and into new simpler\n", "   fields,\n", "4. use Pandas to understand the underlying distrubution\n", "   of certain data.\n", "\n", "\n", "Part of the assignment will require you to \n", "understand the following table for the [Bortle Scale](https://astrotelescopium.com/blogs/news/how-to-use-the-bortle-scale-for-choosing-the-best-stargazing-locations)\n", "for assessing dark sky magnitude:\n", "\n", "\n", "| Bortle Class   | SQM Value       |\n", "|:---:|:------:|\n", "| 1   | >21.9   |\n", "| 2   | 21.9-21.50 |\n", "| 3   | 21.49-21.30 |\n", "| 4   | 21.29-20.80 |\n", "| 4.5 | 20.79-20.10 |\n", "| 5   | 20.09-19.10 |\n", "| 6+  | <19.10 |\n", "\n", "**&#167; Task:**  **Use the file of URLs from the first assignment to load the data from 2014-2024 and store it all into a single file.**\n", "\n", "Use Pandas [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to load _all_ the data into a single DataFrame, then\n", "store that DataFrame into a single file named `2014_to_2024_gan_data.csv`.\n", "\n", "**Note:** You must [`drop_duplicates()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html) \n", "**and** [`reset_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html) before save the file!\n", "\n", "\n", "**&#167; Task:**  **Convert categorical fields to numeric ones.**\n", "\n", "You might have noticed that the `CloudCover` column has 4 possible categorical values.\n", "If you execute `df['CloudCover'].value_counts()` (where `df` is the \n", "2014-2024 GaN DataFrame), you will see \"clear\", \"1/4 sky\", \"1/2 of sky\" and \"over 1/2\n", "of sky\" as the values.\n", "\n", "We will convert these to numeric values using the following guidance:\n", "\n", "* \"clear\" &#8594; 0\n", "* \"1/4 of sky\" &#8594; 0.25\n", "* \"1/2 of sky\" &#8594; 0.50\n", "* \"over 1/2 of sky\" &#8594; 0.75\n", "\n", "To do this, you will want to study [`DataFrame.apply()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) and you may\n", "optionally find [`DataFrame.assign()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html) useful.\n", "\n", "However, you choose to do it, the DataFrame should contain a new\n", "column called `CloudCoverPct` with the converted values.\n", "\n", "\n", "**&#167; Task:**  **Convert `Constellation` to numeric binary values (binarize the column).**\n", "\n", "You will convert the 15 `Constellation` values to columns which \n", "contain a binary value.  For example, `Leo` is present in over\n", "30k data points.  Thus a `1` will be present in the rows\n", "where `Leo` appeared and a `0` everywhere else.\n", "\n", "To accomplish this, you will find [`Pandas.get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to be \n", "superior at accomplishing this goal in a single line of code.\n", "You must prefix the column name with `\"const\"` -- doing\n", "so is easy with the `prefix` parameter of `get_dummies()`.  For example,\n", "the constellation `Leo` would become a binary valued column\n", "`const_Leo`.  Merge all the new columns into the 2014-2024\n", "dataset.\n", "\n", "\n", "**&#167; Task:**  **Create 5 binary columns `loc_urban`, `loc_suburban`, `loc_rural`, `loc_remote` and `loc_unknown`.**\n", "\n", "There is a tremedous amount of information in the `LocationComment` column -- more\n", "than we have time to work on, but because it appears the field is an open\n", "response field, various data appear there (including useless and unwanted data).\n", "\n", "I have provided a function for you to apply called `assign_location()`. \n", "The [helper notebook on Github]() will show you the way. \n", "\n", "Use the function in the context of the following operations:\n", "\n", "(a) convert all `LocationComment` to a single string using `assign_location()`,\n", "(b) use `fillna(\"unknown\")` to use the string `\"unknown\"` as a placeholder,\n", "(c) use `get_dummies()` to make the values binary, **note: you must prefix the new columns with `loc`**,\n", "(d) merge the new columns from (c) in the DataFrame using `concat()`.\n", "\n", "\n", "**&#167; Task:**  **Merge `LocalDate` and `LocalTime` and convert to a `datetime` object.**\n", "\n", "You can see that `LocalDate` and `LocalTime` are separate fields and \n", "also not seen as `datetime` objects to Python.  This is a common task\n", "that is often necessary in order to ask questions that are time-related (and\n", "for plotting time series data).\n", "\n", "You must merge the two columns, but luckily they are already strings, so\n", "Pandas will allow syntax like `df.col1 + df.col2` which is the same\n", "string concatenation behavior as in standard Python.\n", "\n", "Also, luckily, [`pd.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) is a smart swiss army knife such \n", "that if you provide a _good enough looking date string_ it will be smart enough\n", "to properly convert it to a dateime object. \n", "\n", "In our case `\"2021-01-01 23:33\"` is a _good enough date string_.\n", "\n", "Do not overthink this part.  Simply concatenate the two local time/date\n", "columns with a space `\" \"` in between and call `pd.to_datetime()`.  The\n", "result will be the new column to add to your dataset.\n", "\n", "\n", "**&#167; Task:**  **Convert missing `SQMReading` values to `-1`.**\n", "\n", "Since there were no requirements in the data to provide SQM Readings,\n", "there are a lot of missing data.  Instead of removing these rows,\n", "we will fill them with an invalid value of `-1`.\n", "\n", "You may find [`fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) useful.\n", "\n", "\n", "**&#167; Task:**  **Store a new dataset file with a reduced set columns which include our numeric ones.** \n", "\n", "Now that we have engineered a decent dataset using the \n", "techniques above, it is now time to produce a file so\n", "it can be reused and reloaded, preserving the fruits of\n", "our labor.\n", "\n", "You will use `to_csv()` to produce a new file called `\"2014_to_2024_gan_data_working.csv\"`\n", "to represent our working data file for future use and analysis.  It will have\n", "only numeric and date date.\n", "\n", "  The new file will **only** have the following 27 columns:  \n", "\n", "    'Latitude',\n", "    'Longitude',\n", "    'Elevation(m)',\n", "    'LocalDateTime',\n", "    'LimitingMag',\n", "    'SQMReading',\n", "    'CloudCoverPct',\n", "    'const_Bootes',\n", "    'const_Canis Major',\n", "    'const_Crux',\n", "    'const_Cygnus',\n", "    'const_Gemini',\n", "    'const_Grus',\n", "    'const_Hercules',\n", "    'const_Leo',\n", "    'const_None',\n", "    'const_Orion',\n", "    'const_Pegasus',\n", "    'const_Perseus',\n", "    'const_Sagittarius',\n", "    'const_Scorpius',\n", "    'const_Taurus',\n", "    'loc_remote',\n", "    'loc_rural',\n", "    'loc_suburban',\n", "    'loc_unknown',\n", "    'loc_urban'\n", "\n", "\n", "\n", "### (20%) Complete the online assessment \n", "\n", "\n", "Please ZIP the folder and subfolder for your assignment and submit it directly to Blackboard.\n", "\n", "Once you are done with the coding part of the assignment, you will need to complete the online assessment for\n", "the final 4 points (20%) of your grade.\n", "\n", "**&#167; Task:**  **Turn in your solution and complete the online HW1 assessment.**\n", "\n", "\n", "\n", "### (0%) BONUS: Normalize column names in working dataset. \n", "\n", "You might notice a few inconsistencies \n", "in column naming in your final dataset.\n", "\n", "While this is not desireable, for the\n", "assignment, I allowed for this variation.\n", "\n", "However, a better way would be to normalize \n", "the names -- that is make them consistent\n", "with one another so that they appear to represent \n", "a logic when dealing with names.\n", "\n", "Some preferred guides to do this suggest:\n", "\n", "* names that are all lowercase\n", "* `\"_\"` (underscore) separating names (such as `LocalTime` being `local_time`\n", "* using meaningful abbreviations when needed\n", "\n", "\n", "You can update the column names for bonus points -- make\n", "them consistent and follow the guides above OR if you\n", "choose a different style, include that in your submission.\n", "\n", "You will turn in a notebook with the code that\n", "modifies the column names to the chosen style\n", "**and** stores that in a file `2014_to_2024_gan_data_final.csv`.\n", "\n", "**You may earn up to 2 bonus points depending on your solution.**\n", "\n", "**&#167; Task:**  **Normalize the column names and store the new dataset to a file called `2014_to_2024_gan_data_final.csv`.**\n", "\n", "Turn this in with your normal HW1 notebook code.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}